{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proceso de decisiones de Markov\n",
    "**Nombre:** David Egas \n",
    "**Asignatura:** Inteligencia Artificial\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definicion:\n",
    "El proceso de decisiones de Markov es un formalismo matemático para la toma de decisiones, es una extensión de las cadenas de Markov. Un modelo de decisión de Markov contempla el resultado estocástico de las acciones, describiéndolo mediante funciones probabilísticas de transición de estados. El resultado de la planificación en un MDP no es una secuencia de acciones a ejecutar como sucede en la planificación clásica (Fikes & Nilsson 1971), sino una política que determina la acción a seleccionar en función del estado actual que va tomando el sistema a lo largo de la ejecución de la tarea. Estos modelos no dependen de acciones pasadas.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función del agente de acción en los modelos de Markov\n",
    "En general, en los problemas de decisión las acciones adoptadas por el agente determinan no sólo la recompensa inmediata sino el siguiente estado del entorno, al menos probabilísticamente. Por lo tanto, el agente toma en cuenta el siguiente estado y la recompensa cuando decide tomar una acción determinada. En estos casos, el modelo óptimo considerado para toda la ejecución determinará cómo tomar en cuenta los valores obtenidos en el futuro. El agente debe ser capaz de aprender a partir de recompensas 201 demoradas: o sea, puede obtener una secuencia de pequeñas recompensas inmediatas primero, para finalmente llegar a un estado donde se obtiene un valor de recompensa alto. Es decir, el agente debe aprender cuál de las acciones es deseable tomando en cuenta la o las recompensas que pueden obtenerse en un futuro arbitrariamente lejano.\n"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Propiedad del modelo de Markov\n",
    "La propiedad de Markov nos muestra que el futuro es independiente del pasado, dado el presente, lo cual se expresa en la siguiente formula:\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "La cual significa que el estado actual (representado por Sₜ) contiene toda la información relevante de los estados pasados (S₁,….. Sₜ), por lo tanto ya no nos serviría tener mayor información de los estados pasados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplificando lo anterior:\n",
    "Un proceso de Markov es un proceso sin memoria y aleatorio; en otras palabras es una secuencia de estados aleatorios que posee la propiedad de Markov.\n",
    "Se podría definir el proceso de Markov como una tupla <S,P>\n",
    "- S es una lista de estados a los cuales puede pertenecer.\n",
    "- P es una matriz de transición de estado.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicación de los modelos de markov \n",
    "Los modelos de markov son muy útiles para sistemas en diferentes campos, por nombrar algunos ejemplos tenemos:\n",
    "\n",
    "- Meteorología: modelos climtológicos basicos \n",
    "- Internet: el pagerank de una página web se define a través de una cadena de markov.\n",
    "- Simulacion:solución analítica a ciertos problemas de simulación.\n",
    "- Música: diversos algoritmos de composición musical usan cadenas de markov.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementación sencilla "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q  :\n",
      "[[  0.      0.      0.      0.    258.44    0.   ]\n",
      " [  0.      0.      0.    321.8     0.    207.752]\n",
      " [  0.      0.    500.    321.8     0.      0.   ]\n",
      " [  0.    258.44  401.      0.    258.44    0.   ]\n",
      " [207.752   0.      0.    321.8     0.      0.   ]\n",
      " [  0.    258.44    0.      0.      0.      0.   ]]\n",
      "Normed Q :\n",
      "[[  0.       0.       0.       0.      51.688    0.    ]\n",
      " [  0.       0.       0.      64.36     0.      41.5504]\n",
      " [  0.       0.     100.      64.36     0.       0.    ]\n",
      " [  0.      51.688   80.2      0.      51.688    0.    ]\n",
      " [ 41.5504   0.       0.      64.36     0.       0.    ]\n",
      " [  0.      51.688    0.       0.       0.       0.    ]]\n"
     ]
    }
   ],
   "source": [
    "# Markov Decision Process (MDP) - The Bellman equations adapted to\n",
    "# Q Learning.Reinforcement Learning with the Q action-value(reward) function.\n",
    "# Copyright 2018 Denis Rothman MIT License. See LICENSE.\n",
    "import numpy as ql\n",
    "# R is The Reward Matrix for each state\n",
    "R = ql.matrix([ [0,0,0,0,1,0],\n",
    "\t\t[0,0,0,1,0,1],\n",
    "\t\t[0,0,100,1,0,0],\n",
    "\t\t[0,1,1,0,1,0],\n",
    "\t\t[1,0,0,1,0,0],\n",
    "\t\t[0,1,0,0,0,0] ])\n",
    "\n",
    "# Q is the Learning Matrix in which rewards will be learned/stored\n",
    "Q = ql.matrix(ql.zeros([6,6]))\n",
    "\n",
    "# Gamma : It's a form of penalty or uncertainty for learning\n",
    "# If the value is 1 , the rewards would be too high.\n",
    "# This way the system knows it is learning.\n",
    "gamma = 0.8\n",
    "\n",
    "# agent_s_state. The agent the name of the system calculating\n",
    "# s is the state the agent is going from and s' the state it's going to\n",
    "# this state can be random or it can be chosen as long as the rest of the choices\n",
    "# are not determined. Randomness is part of this stochastic process\n",
    "agent_s_state = 1\n",
    "\n",
    "# The possible \"a\" actions when the agent is in a given state\n",
    "def possible_actions(state):\n",
    "    current_state_row = R[state,]\n",
    "    possible_act = ql.where(current_state_row >0)[1]\n",
    "    return possible_act\n",
    "\n",
    "# Get available actions in the current state\n",
    "PossibleAction = possible_actions(agent_s_state)\n",
    "\n",
    "# This function chooses at random which action to be performed within the range \n",
    "# of all the available actions.\n",
    "def ActionChoice(available_actions_range):\n",
    "    if(sum(PossibleAction)>0):\n",
    "        next_action = int(ql.random.choice(PossibleAction,1))\n",
    "    if(sum(PossibleAction)<=0):\n",
    "        next_action = int(ql.random.choice(5,1))\n",
    "    return next_action\n",
    "\n",
    "# Sample next action to be performed\n",
    "action = ActionChoice(PossibleAction)\n",
    "\n",
    "# A version of Bellman's equation for reinforcement learning using the Q function\n",
    "# This reinforcement algorithm is a memoryless process\n",
    "# The transition function T from one state to another\n",
    "# is not in the equation below.  T is done by the random choice above\n",
    "\n",
    "def reward(current_state, action, gamma):\n",
    "    Max_State = ql.where(Q[action,] == ql.max(Q[action,]))[1]\n",
    "\n",
    "    if Max_State.shape[0] > 1:\n",
    "        Max_State = int(ql.random.choice(Max_State, size = 1))\n",
    "    else:\n",
    "        Max_State = int(Max_State)\n",
    "    MaxValue = Q[action, Max_State]\n",
    "    \n",
    "    # Bellman's MDP based Q function\n",
    "    Q[current_state, action] = R[current_state, action] + gamma * MaxValue\n",
    "\n",
    "# Rewarding Q matrix\n",
    "reward(agent_s_state,action,gamma)\n",
    "\n",
    "\n",
    "# Leraning over n iterations depending on the convergence of the system\n",
    "# A convergence function can replace the systematic repeating of the process\n",
    "# by comparing the sum of the Q matrix to that of Q matrix n-1 in the\n",
    "# previous episode\n",
    "for i in range(50000):\n",
    "    current_state = ql.random.randint(0, int(Q.shape[0]))\n",
    "    PossibleAction = possible_actions(current_state)\n",
    "    action = ActionChoice(PossibleAction)\n",
    "    reward(current_state,action,gamma)\n",
    "    \n",
    "# Displaying Q before the norm of Q phase\n",
    "print(\"Q  :\")\n",
    "print(Q)\n",
    "\n",
    "# Norm of Q\n",
    "print(\"Normed Q :\")\n",
    "print(Q/ql.max(Q)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explicación:\n",
    "**R:** es la matriz de recompensa.\n",
    "**Q:** hereda la misma estructura que R, pero todos los valores están configurados 0 ya que esta es una matriz de aprendizaje. Contendrá progresivamente los resultados del proceso de decisión. \n",
    "**La variable gamma:** es un recordatorio doble de que el sistema está aprendiendo y que sus decisiones solo tienen un 80% de posibilidades de ser correctas cada vez. \n",
    "Como muestra el siguiente código, el sistema explora las posibles acciones durante el proceso.\n",
    "\n",
    "Una vez que se repite el proceso y hasta que finalice el proceso de aprendizaje, el programa imprimirá el resultado Qy el resultado normalizado. El resultado normalizado es el proceso de dividir todos los valores por la suma de los valores encontrados. El resultado sale como un porcentaje normalizado.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusión\n",
    "La propiedad de Markov dice: “No importa qué acciones se hayan llevado a cabo para alcanzar el estado actual, porque el estado actual es suficiente para decidir cuál debe de ser la acción futura”.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliografía:\n",
    "- [Ejemplo Implementado:] https://hub.packtpub.com/enhancing-markovs-decision-process-with-bellman-equation-tutorial/\n",
    "\n",
    "- https://inaoe.repositorioinstitucional.mx/jspui/bitstream/1009/588/1/CuayaSG.pdf?fbclid=IwAR3Ugq184OsLty_D48lv17k2nwR1_JroJmLi0MLOQQHR-Hh32642L6H_rJE\n",
    "\n",
    "- https://es.coursera.org/lecture/razonamiento-artificial/procesos-de-decision-de-markov-Vqv8j?fbclid=IwAR1K40lkVc9Ad30t500QHGq2NZ3plAs9tiHeVr5fcLn2PNCATicWV2heurg\n",
    "\n",
    "- https://medium.com/aprendizaje-por-refuerzo-introducci%C3%B3n-al-mundo-del/aprendizaje-por-refuerzo-procesos-de-decisi%C3%B3n-de-markov-parte-1-8a0aed1e6c59"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
